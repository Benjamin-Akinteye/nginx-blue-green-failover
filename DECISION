Blue/Green Failover Implementation Rationale

This document outlines the key decisions made in configuring the Nginx reverse proxy and the Docker Compose setup to meet the strict Blue/Green failover requirements.

1. Configuration Templating with envsubst

Decision: Use a multi-stage approach in docker-compose.yml with a dedicated nginx_setup service.

Rationale: The requirement to template the Nginx configuration based on the $ACTIVE_POOL environment variable and support nginx -s reload meant the configuration file must be finalized before the main Nginx process starts. The standard Nginx image doesn't include envsubst. By using a lightweight alpine/git image in the nginx_setup service, we can reliably use envsubst to replace ${ACTIVE_POOL} (and other variables) in nginx.conf.template and output the final default.conf file, which the main Nginx service then mounts and runs.
2. Fast Failover MechanicsDecision: Employ aggressive upstream parameters in nginx.conf.template.Configuration: max_fails=1 and fail_timeout=1s on the active upstream server (app_blue in the default blue_pool).Rationale: To detect Blue's failure quickly (essential for meeting the zero-downtime requirement), the active server is marked as down after a single failure within a 1-second window. This ensures Nginx moves to the backup almost instantly upon detecting a connection error, timeout, or 5xx response.
3. Zero-Failure Client Request RequirementDecision: Use a comprehensive proxy_next_upstream and proxy_next_upstream_tries policy combined with low proxy timeouts.Configuration:proxy_next_upstream timeout error http_500 http_502 http_503 http_504;proxy_next_upstream_tries 2;proxy_connect_timeout 1s;, proxy_read_timeout 2s;Rationale: The core requirement is that an error on Blue must not result in a non-200 for the client. The proxy_next_upstream directive tells Nginx to transparently retry the request on the next server (which will be Green) if Blue returns any of the specified transient errors or timeouts. proxy_next_upstream_tries 2 ensures one attempt on Blue and one retry on Green, guaranteeing the client receives a 200 from Green if the retry is successful. The tight timeouts prevent the client request from exceeding the implicit 10-second limit while waiting for a retry.
4. Header PreservationDecision: Disable proxy buffering and explicitly forward headers.Configuration:proxy_pass_request_headers on;proxy_buffering off;Rationale: Nginx's buffering can sometimes interfere with application-specific headers. Explicitly enabling proxy_pass_request_headers ensures all incoming client headers are forwarded to the upstream. More importantly, setting proxy_buffering off is a robust way to ensure Nginx does not modify or strip custom headers (X-App-Pool, X-Release-Id) from the upstream response before sending them to the client.
5. Upstream Role ConfigurationDecision: Use the backup parameter dynamically.Configuration: Two upstreams (blue_pool and green_pool) are defined. The one corresponding to $ACTIVE_POOL (e.g., blue_pool when ACTIVE_POOL=blue) designates the other pool as backup.Rationale: This directly satisfies the requirement for Primary/Backup roles and allows the CI to perform a full switch (Blue $\rightarrow$ Green Primary) simply by changing the $ACTIVE_POOL environment variable and triggering a configuration reload.